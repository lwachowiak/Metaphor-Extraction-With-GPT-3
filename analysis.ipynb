{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "import math\n",
    "import numpy as np\n",
    "from gensim import matutils\n",
    "import gensim.downloader\n",
    "import time\n",
    "import requests\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import statistics\n",
    "import wandb\n",
    "openai.api_key = openai.api_key_path=\"GPT3.txt\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15602754"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = gensim.downloader.load('glove-wiki-gigaword-300')\n",
    "word_vectors.similarity('table', 'spain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv dataset\n",
    "df = pd.read_csv('Data/crawled_metaphors_selected_three_examples.csv', sep=\";\", index_col=0)\n",
    "df_non_metaphoric = pd.read_csv('Data/non_metaphoric_examples.csv', sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Domain</th>\n",
       "      <th>Target Domain</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>destruction</td>\n",
       "      <td>intoxication</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>size</td>\n",
       "      <td>amount</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>plants</td>\n",
       "      <td>beliefs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>goal</td>\n",
       "      <td>success</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>areas</td>\n",
       "      <td>subjects</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source Domain Target Domain  counts\n",
       "38    destruction  intoxication       4\n",
       "129          size        amount       4\n",
       "108        plants       beliefs       4\n",
       "53           goal       success       4\n",
       "6           areas      subjects       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many different unique combinations of source and target\n",
    "combinations = df.groupby(['Source Domain', 'Target Domain']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "combinations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of target domains in VUA non-metaphoric: 47\n",
      "Number of target domains in Metaphor List: 91\n",
      "Number of source domains in Metaphor List: 94\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of target domains in VUA non-metaphoric:\",len(df_non_metaphoric['Target Domain'].unique()))\n",
    "print(\"Number of target domains in Metaphor List:\",len(df['Target Domain'].unique()))\n",
    "print(\"Number of source domains in Metaphor List:\",len(df['Source Domain'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Domain</th>\n",
       "      <th>Target Domain</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>destruction</td>\n",
       "      <td>intoxication</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>size</td>\n",
       "      <td>amount</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>plants</td>\n",
       "      <td>beliefs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>goal</td>\n",
       "      <td>success</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>areas</td>\n",
       "      <td>subjects</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>object</td>\n",
       "      <td>ideas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>insanity</td>\n",
       "      <td>strong emotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>burden</td>\n",
       "      <td>intoxication</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>up</td>\n",
       "      <td>rational</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>insanity</td>\n",
       "      <td>excitement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Source Domain   Target Domain  counts\n",
       "38    destruction    intoxication       4\n",
       "129          size          amount       4\n",
       "108        plants         beliefs       4\n",
       "53           goal         success       4\n",
       "6           areas        subjects       4\n",
       "..            ...             ...     ...\n",
       "97         object           ideas       2\n",
       "65       insanity  strong emotion       2\n",
       "14         burden    intoxication       2\n",
       "143            up        rational       2\n",
       "63       insanity      excitement       1\n",
       "\n",
       "[113 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split combinations randomly into train of size 40 and test set\n",
    "train = combinations.sample(n=40, random_state=1)\n",
    "test = combinations.drop(train.index)\n",
    "print(len(train), len(test))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source domain overlap train/test: 11\n",
      "Target domain overlap train/test: 15\n"
     ]
    }
   ],
   "source": [
    "# overlap in source domains between test and train\n",
    "s_test=test['Source Domain'].unique()\n",
    "s_train=train['Source Domain'].unique()\n",
    "# how many source domains are in both sets\n",
    "print(\"Source domain overlap train/test:\",len(set(s_test).intersection(s_train)))\n",
    "t_test = test['Target Domain'].unique()\n",
    "t_train = train['Target Domain'].unique()\n",
    "# how many target domains are in both sets\n",
    "print(\"Target domain overlap train/test:\",len(set(t_test).intersection(t_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, val, and test tests \n",
    "train_df = pd.DataFrame(columns=[\"Source Domain\", \"Target Domain\", \"Title\", \"Metaphor\", \"Example\"])\n",
    "for i, row in train.iterrows():\n",
    "    samples = df[(df[\"Source Domain\"]==row[\"Source Domain\"]) & (df[\"Target Domain\"]==row[\"Target Domain\"])] \n",
    "    train_df = train_df.append(samples.sample(n=min(3, len(samples)), random_state=1))\n",
    "\n",
    "test_df = pd.DataFrame(columns=[\"Source Domain\", \"Target Domain\", \"Title\", \"Metaphor\", \"Example\"])\n",
    "valid_df = pd.DataFrame(columns=[\"Source Domain\", \"Target Domain\", \"Title\", \"Metaphor\", \"Example\"])\n",
    "for i, row in test.iterrows():\n",
    "    samples = df[(df[\"Source Domain\"]==row[\"Source Domain\"]) & (df[\"Target Domain\"]==row[\"Target Domain\"])] \n",
    "    # split into samples for test and val; 1 sample for val, 2 for test\n",
    "    test_samples = samples.sample(n=min(2, len(samples)), random_state=1)\n",
    "    test_df = test_df.append(test_samples)\n",
    "    valid_df = valid_df.append(samples.drop(test_samples.index))\n",
    "valid_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute non-metaphoric samples across train, val, and test\n",
    "train_df = train_df.append(df_non_metaphoric[:15])\n",
    "valid_df = valid_df.append(df_non_metaphoric[15:30])\n",
    "test_df = test_df.append(df_non_metaphoric[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of train:  132\n",
      "Lenght of valid:  120\n",
      "Lenght of test:  244\n"
     ]
    }
   ],
   "source": [
    "print(\"Lenght of train: \", len(train_df))\n",
    "print(\"Lenght of valid: \", len(valid_df))\n",
    "print(\"Lenght of test: \", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCC Dataset for Additional Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Example</th>\n",
       "      <th>Source Domain</th>\n",
       "      <th>Target Domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So, you advocate for the ability to deny peopl...</td>\n",
       "      <td>['ABYSS', 'DISEASE']</td>\n",
       "      <td>POVERTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I found few things wrong with \"Law,\" written b...</td>\n",
       "      <td>['LIGHT']</td>\n",
       "      <td>WEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I, personally, do not see people who \"are born...</td>\n",
       "      <td>['PHYSICAL_LOCATION', 'PHYSICAL_LOCATION']</td>\n",
       "      <td>WEALTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now if you \"eliminate those who already have t...</td>\n",
       "      <td>['ABYSS', 'ABYSS', 'NATURAL_PHYSICAL_FORCE', '...</td>\n",
       "      <td>POVERTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The NBS report makes it quite clear that with ...</td>\n",
       "      <td>['MACHINE', 'ABYSS', 'ABYSS']</td>\n",
       "      <td>POVERTY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Example  \\\n",
       "0  So, you advocate for the ability to deny peopl...   \n",
       "1  I found few things wrong with \"Law,\" written b...   \n",
       "2  I, personally, do not see people who \"are born...   \n",
       "3  Now if you \"eliminate those who already have t...   \n",
       "4  The NBS report makes it quite clear that with ...   \n",
       "\n",
       "                                       Source Domain Target Domain  \n",
       "0                               ['ABYSS', 'DISEASE']       POVERTY  \n",
       "1                                          ['LIGHT']        WEALTH  \n",
       "2         ['PHYSICAL_LOCATION', 'PHYSICAL_LOCATION']        WEALTH  \n",
       "3  ['ABYSS', 'ABYSS', 'NATURAL_PHYSICAL_FORCE', '...       POVERTY  \n",
       "4                      ['MACHINE', 'ABYSS', 'ABYSS']       POVERTY  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCC_df=pd.read_csv('Data/LCC_Metaphor_Dataset.small/en_small.csv', sep=\";\", index_col=0)\n",
    "LCC_es_df=pd.read_csv('Data/LCC_Metaphor_Dataset.small/es_small.csv', sep=\";\", index_col=0)\n",
    "LCC_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Target Domains in LCC small: 30\n",
      "Number of Target Domains in LCC small Spanish: 11\n"
     ]
    }
   ],
   "source": [
    "# how many different target domains are in LCC_df\n",
    "print(\"Number of Target Domains in LCC small:\", len(LCC_df[\"Target Domain\"].unique()))\n",
    "print(\"Number of Target Domains in LCC small Spanish:\", len(LCC_es_df[\"Target Domain\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TAXATION' 'POVERTY' 'MONEY' 'WEALTH' 'TAXPAYERS' 'DEBT' 'TAXES'\n",
      " 'ELECTIONS' 'BUREAUCRACY' 'GOVERNMENT' 'DEMOCRACY']\n"
     ]
    }
   ],
   "source": [
    "# print all target domains in LCC small es \n",
    "print(LCC_es_df[\"Target Domain\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ABYSS', 'DISEASE'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_domains_LCC=LCC_df[\"Source Domain\"].unique()\n",
    "source_domains_LCC_es=LCC_es_df[\"Source Domain\"].unique()\n",
    "from ast import literal_eval\n",
    "for i in range(len(source_domains_LCC)):\n",
    "    source_domains_LCC[i]=set(literal_eval(source_domains_LCC[i]))\n",
    "for i in range(len(source_domains_LCC_es)):\n",
    "    source_domains_LCC_es[i]=set(literal_eval(source_domains_LCC_es[i]))\n",
    "\n",
    "source_domains_LCC[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Source Domains in LCC small: 101\n",
      "Number of Source Domains in LCC small Spanish: 101\n"
     ]
    }
   ],
   "source": [
    "# a joined set of all source domains in LCC\n",
    "source_domains_LCC_set=set()\n",
    "source_domains_LCC_set_es=set()\n",
    "for i in range(len(source_domains_LCC)):\n",
    "    source_domains_LCC_set=source_domains_LCC_set.union(source_domains_LCC[i])\n",
    "for i in range(len(source_domains_LCC_es)):\n",
    "    source_domains_LCC_set_es=source_domains_LCC_set_es.union(source_domains_LCC_es[i])\n",
    "print(\"Number of Source Domains in LCC small:\", len(source_domains_LCC_set))\n",
    "print(\"Number of Source Domains in LCC small Spanish:\", len(source_domains_LCC_set_es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in LCC_df_300: 0\n",
      "Number of Source Domains in LCC_df_300: 90\n",
      "Length of LCC_df_300: 284\n"
     ]
    }
   ],
   "source": [
    "# create df of 300 samples from LCC, 10 per target domain\n",
    "LCC_df_300 = pd.DataFrame(columns=[\"Source Domain\", \"Target Domain\", \"Example\"])\n",
    "for i in range(len(LCC_df[\"Target Domain\"].unique())):\n",
    "    samples = LCC_df[LCC_df[\"Target Domain\"]==LCC_df[\"Target Domain\"].unique()[i]] \n",
    "    LCC_df_300 = LCC_df_300.append(samples.sample(n=min(10, len(samples)), random_state=144))\n",
    "duplicates=LCC_df_300.duplicated(subset=[\"Example\"]).sum()\n",
    "print(\"Number of duplicates in LCC_df_300:\", duplicates)\n",
    "# number of source domains in LCC_df_300\n",
    "source_domains_LCC_300=set()\n",
    "for i in range(len(LCC_df_300[\"Source Domain\"].unique())):\n",
    "    source_domains_LCC_300=source_domains_LCC_300.union(set(literal_eval(LCC_df_300[\"Source Domain\"].unique()[i])))\n",
    "print(\"Number of Source Domains in LCC_df_300:\", len(source_domains_LCC_300))\n",
    "print(\"Length of LCC_df_300:\", len(LCC_df_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates in LCC_es_df_110: 0\n",
      "Number of Source Domains in LCC_es_df_110: 67\n",
      "Length of LCC_es_df_110: 110\n"
     ]
    }
   ],
   "source": [
    "# create df of 110 samples from LCC es, 10 per target domain\n",
    "LCC_es_df_110 = pd.DataFrame(columns=[\"Source Domain\", \"Target Domain\", \"Example\"])\n",
    "for i in range(len(LCC_es_df[\"Target Domain\"].unique())):\n",
    "    samples = LCC_es_df[LCC_es_df[\"Target Domain\"]==LCC_es_df[\"Target Domain\"].unique()[i]] \n",
    "    LCC_es_df_110 = LCC_es_df_110.append(samples.sample(n=min(10, len(samples)), random_state=5))\n",
    "duplicates=LCC_es_df_110.duplicated(subset=[\"Example\"]).sum()\n",
    "print(\"Number of duplicates in LCC_es_df_110:\", duplicates)\n",
    "# number of source domains in LCC_es_df_110\n",
    "source_domains_LCC_es_110=set()\n",
    "for i in range(len(LCC_es_df_110[\"Source Domain\"].unique())):\n",
    "    source_domains_LCC_es_110=source_domains_LCC_es_110.union(set(literal_eval(LCC_es_df_110[\"Source Domain\"].unique()[i])))\n",
    "print(\"Number of Source Domains in LCC_es_df_110:\", len(source_domains_LCC_es_110))\n",
    "print(\"Length of LCC_es_df_110:\", len(LCC_es_df_110))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite target domain in lower case\n",
    "for i in range(len(LCC_df_300[\"Target Domain\"])):\n",
    "    LCC_df_300[\"Target Domain\"].iloc[i]=LCC_df_300[\"Target Domain\"].iloc[i].lower()\n",
    "LCC_df_300.reset_index(drop=True, inplace=True)\n",
    "LCC_df_300.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite target domain in lower case\n",
    "for i in range(len(LCC_es_df_110[\"Target Domain\"])):\n",
    "    LCC_es_df_110[\"Target Domain\"].iloc[i]=LCC_es_df_110[\"Target Domain\"].iloc[i].lower()\n",
    "LCC_es_df_110.reset_index(drop=True, inplace=True)\n",
    "LCC_es_df_110.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source_prompt(row):\n",
    "    prompt=\"Extract the conceptual metaphor from the following sentence:\\n\"\n",
    "    prompt+=\"Sentence: \"+row['Example']+\"\\n\"\n",
    "    prompt+=\"Target Domain: \"+str(row['Target Domain'])+\"\\n\"\n",
    "    prompt+=\"Source Domain:\"\n",
    "    completion=str(row['Source Domain'])\n",
    "    return prompt, completion\n",
    "\n",
    "def create_target_prompt(row):\n",
    "    prompt = \"Extract the conceptual metaphor from the following sentence:\\n\"\n",
    "    prompt+=\"Sentence: \"+row['Example']+\"\\n\"\n",
    "    prompt+=\"Source Domain: \"+str(row['Source Domain'])+\"\\n\"\n",
    "    prompt+=\"Target Domain:\"\n",
    "    completion = str(row['Target Domain'])\n",
    "    return prompt, completion\n",
    "\n",
    "def create_full_prompt(row):\n",
    "    prompt = \"Extract the conceptual metaphor from the following sentence:\\n\"\n",
    "    prompt+=\"Sentence: \"+row['Example']+\"\\n\"\n",
    "    completion = \"Target Domain: \"+str(row['Target Domain'])+\"\\n\"\n",
    "    completion+=\"Source Domain: \"+str(row['Source Domain'])\n",
    "    return prompt, completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He recovered his hopes for a peace on earth.\n",
      "Target Domain: hope\n",
      "Source Domain:\n",
      "Completion: possessions\n"
     ]
    }
   ],
   "source": [
    "# create source prompts\n",
    "list_of_source_prompts_train = []\n",
    "list_of_source_completions_train = []\n",
    "list_of_source_prompts_test = []\n",
    "list_of_source_completions_test = []\n",
    "list_of_source_prompts_valid = []\n",
    "list_of_source_completions_valid = []\n",
    "list_of_source_prompts_LCC = []\n",
    "list_of_source_completions_LCC = []\n",
    "list_of_source_prompts_LCC_es = []\n",
    "list_of_source_completions_LCC_es = []\n",
    "\n",
    "\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    list_of_source_prompts_train.append(create_source_prompt(row)[0])\n",
    "    list_of_source_completions_train.append(create_source_prompt(row)[1])\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    list_of_source_prompts_test.append(create_source_prompt(row)[0])\n",
    "    list_of_source_completions_test.append(create_source_prompt(row)[1])\n",
    "\n",
    "for i, row in valid_df.iterrows():\n",
    "    list_of_source_prompts_valid.append(create_source_prompt(row)[0])\n",
    "    list_of_source_completions_valid.append(create_source_prompt(row)[1])\n",
    "    \n",
    "for i, row in LCC_df_300.iterrows():\n",
    "    list_of_source_prompts_LCC.append(create_source_prompt(row)[0])\n",
    "    list_of_source_completions_LCC.append(create_source_prompt(row)[1])\n",
    "\n",
    "for i, row in LCC_es_df_110.iterrows():\n",
    "    list_of_source_prompts_LCC_es.append(create_source_prompt(row)[0])\n",
    "    list_of_source_completions_LCC_es.append(create_source_prompt(row)[1])\n",
    "    \n",
    "print(\"Prompt:\", list_of_source_prompts_train[2])\n",
    "print(\"Completion:\", list_of_source_completions_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: That's not my artwork on there, that's my little niece's artwork.\n",
      "Target Domain: artwork\n",
      "Source Domain:\n",
      "Completion: not metaphoric\n"
     ]
    }
   ],
   "source": [
    "# print prompt and completion for train side by side\n",
    "index=-3\n",
    "print(\"Prompt:\", list_of_source_prompts_train[index])\n",
    "print(\"Completion:\", list_of_source_completions_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: What is great about this resource is that it targets every possible area and route of poverty, rather than focusing on the traditional case studies of African poverty.\n",
      "Target Domain: poverty\n",
      "Source Domain:\n",
      "Completion: ['JOURNEY']\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt:\", list_of_source_prompts_LCC[2])\n",
    "print(\"Completion:\", list_of_source_completions_LCC[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He recovered his hopes for a peace on earth.\n",
      "\n",
      "Completion: Target Domain: hope\n",
      "Source Domain: possessions\n"
     ]
    }
   ],
   "source": [
    "# create full prompts\n",
    "list_of_full_prompts_train = []\n",
    "list_of_full_completions_train = []\n",
    "list_of_full_prompts_test = []\n",
    "list_of_full_completions_test = []\n",
    "list_of_full_prompts_valid = []\n",
    "list_of_full_completions_valid = []\n",
    "list_of_full_prompts_LCC = []\n",
    "list_of_full_completions_LCC = []\n",
    "list_of_full_prompts_LCC_es = []\n",
    "list_of_full_completions_LCC_es = []\n",
    "\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    list_of_full_prompts_train.append(create_full_prompt(row)[0])\n",
    "    list_of_full_completions_train.append(create_full_prompt(row)[1])\n",
    "for i, row in test_df.iterrows():\n",
    "    list_of_full_prompts_test.append(create_full_prompt(row)[0])\n",
    "    list_of_full_completions_test.append(create_full_prompt(row)[1])\n",
    "for i, row in valid_df.iterrows():\n",
    "    list_of_full_prompts_valid.append(create_full_prompt(row)[0])\n",
    "    list_of_full_completions_valid.append(create_full_prompt(row)[1])\n",
    "for i, row in LCC_df_300.iterrows():\n",
    "    list_of_full_prompts_LCC.append(create_full_prompt(row)[0])\n",
    "    list_of_full_completions_LCC.append(create_full_prompt(row)[1])\n",
    "for i, row in LCC_es_df_110.iterrows():\n",
    "    list_of_full_prompts_LCC_es.append(create_full_prompt(row)[0])\n",
    "    list_of_full_completions_LCC_es.append(create_full_prompt(row)[1])\n",
    "print(\"Prompt:\", list_of_full_prompts_train[2])\n",
    "print(\"Completion:\", list_of_full_completions_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fewshot_prompts(prompts_train, completions_train, prompts_test, completions_test, train_indices, extra_def):\n",
    "    prompts = []\n",
    "    completions = []\n",
    "    train_prompt = \"\"\n",
    "    if extra_def:\n",
    "        train_prompt = 'In cognitive linguistics, conceptual metaphor, or cognitive metaphor, refers to the understanding of one idea, or conceptual domain, in terms of another. An example of this is the understanding of quantity in terms of directionality (e.g. \"the price of peace is rising\") or the understanding of time in terms of money (e.g. \"I spent time at work today\"). This idea, and a detailed examination of the underlying processes, was first extensively explored by George Lakoff and Mark Johnson in their work Metaphors We Live By in 1980.\\n'\n",
    "    for i in train_indices:\n",
    "        train_prompt+=prompts_train[i]+\" \"+completions_train[i]+\"\\n\"\n",
    "    for i in range(len(prompts_test)):\n",
    "        prompts.append(train_prompt+prompts_test[i])\n",
    "        completions.append(completions_test[i])\n",
    "    return prompts, completions\n",
    "\n",
    "\n",
    "# additional prompt variant for step by step reasoning generations\n",
    "def create_reasoning_prompts(prompts_test, completions_test):\n",
    "    prompts = []\n",
    "    completions = []\n",
    "    train_prompt = '''Prompt: Extract the conceptual metaphor from the following sentence:\n",
    "Sentence: He recovered his hopes for a peace on earth.\n",
    "Target Domain: hope\n",
    "Reasoning: In the sentence above, the hopes are recovered. Recovering has a basic physical sentence, that is, getting back an object that belonged to you previously. Thus, hopes are talked about as possessions or physical objects. \n",
    "Source Domain: possessions\n",
    "\n",
    "Prompt: Extract the conceptual metaphor from the following sentence:\n",
    "Sentence:  He finally found the key to the problem.\n",
    "Target Domain: problem\n",
    "Reasoning: The problem has a key, thus is a container that can be opened. \n",
    "Source Domain: container\n",
    "\n",
    "Prompt: Extract the conceptual metaphor from the following sentence:\n",
    "Sentence: You have to weigh the pros and cons.\n",
    "Target Domain: comparison\n",
    "Reasoning: In the sentence above, pros and cons are being compared. Instead of using the abstract word compare, the sentence uses the verb “to weight” usually used to describe measuring the weight of physical objects. Here, however, arguments, thus, non-physical entities, are being measures.\n",
    "Source Domain: measuring weight \n",
    "\n",
    "Prompt: Extract the conceptual metaphor from the following sentence:\n",
    "Sentence: the contagion of democratic ideas\n",
    "Target Domain: belief\n",
    "Reasoning: In the sentence above, ideas are described as something that is contagious, like a disease. \n",
    "Source Domain: disease\n",
    "\n",
    "Prompt: Extract the conceptual metaphor from the following sentence:\n",
    "Sentence: Follow your reasoning where it takes you.\n",
    "Target Domain: logic\n",
    "Reasoning: In the above sentence, logic refers to reasoning. Reasoning is described as something that you can follow, just like a path in the physical world.\n",
    "Source Domain: path\n",
    "\n",
    "Prompt: Extract the conceptual metaphor from the following sentence:\n",
    "Sentence: But he said, don't wash it I wanna wear it.\n",
    "Target Domain: washing\n",
    "Reasoning: Washing is used in a literal sense and no metaphoric transfer is taking place.\n",
    "Source Domain: not metaphoric\\n\\n'''\n",
    "    for i in range(len(prompts_test)):\n",
    "        # replace Source Domain with Reasoning in prompts_test[i]\n",
    "        p_test=prompts_test[i].replace(\"Source Domain\", \"Reasoning\")\n",
    "        prompts.append(train_prompt+p_test)\n",
    "        completions.append(completions_test[i])\n",
    "    return prompts, completions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_indices=[0,15,30,-1]\n",
    "prompts, completions = create_fewshot_prompts(prompts_train = list_of_source_prompts_train, completions_train = list_of_source_completions_train, \n",
    "                prompts_test = list_of_source_prompts_valid, completions_test = list_of_source_completions_valid, train_indices=train_indices, extra_def=True)\n",
    "print(len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In cognitive linguistics, conceptual metaphor, or cognitive metaphor, refers to the understanding of one idea, or conceptual domain, in terms of another. An example of this is the understanding of quantity in terms of directionality (e.g. \"the price of peace is rising\") or the understanding of time in terms of money (e.g. \"I spent time at work today\"). This idea, and a detailed examination of the underlying processes, was first extensively explored by George Lakoff and Mark Johnson in their work Metaphors We Live By in 1980.\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: I've lost all hope of a solution.\n",
      "Target Domain: hope\n",
      "Source Domain: possessions\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Time heals all wounds.\n",
      "Target Domain: time\n",
      "Source Domain: changer\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He's really high.\n",
      "Target Domain: euphoria\n",
      "Source Domain: up\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: But he he said,  don't wash it I wanna wear it.\n",
      "Target Domain: washing\n",
      "Source Domain: not metaphoric\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: This belief has taken root in my mind.\n",
      "Target Domain: beliefs\n",
      "Source Domain:\n",
      "plants\n"
     ]
    }
   ],
   "source": [
    "print(prompts[5])\n",
    "print(completions[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing that GPT3 works\n",
    "GPT3_completions=[]\n",
    "for p in prompts[:5]:\n",
    "     c = openai.Completion.create(\n",
    "             model=\"text-davinci-002\",\n",
    "             prompt=p,\n",
    "             max_tokens=14,\n",
    "             temperature=0\n",
    "         )\n",
    "     GPT3_completions.append(c)\n",
    "df_results = valid_df.copy().reset_index()\n",
    "# append GPT3_completions to df_results [trainings_units:len(GPT3_completions)]\n",
    "if len(GPT3_completions)>0:\n",
    "    for i in range(len(GPT3_completions)):\n",
    "        df_results.loc[i, 'GPT3 Source Completion'] = GPT3_completions[i].choices[0].text\n",
    "    df_results[:len(GPT3_completions)][[\"Target Domain\", \"Source Domain\",\"GPT3 Source Completion\", \"Example\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average similarity between the GPT3 completion and the source domain\n",
    "def compute_embedding_similarity(df_results, task_type):\n",
    "    '''\n",
    "    df_results: dataframe containing the GPT3 completions\n",
    "    result_samples: number of samples to be evaluated\n",
    "    '''\n",
    "    for i in range(len(df_results)):\n",
    "        if task_type == \"Source\":\n",
    "            gold = df_results.loc[i, 'Source Domain']\n",
    "        elif task_type == \"Target\":\n",
    "            gold = df_results.loc[i, 'Target Domain']\n",
    "        elif task_type == \"Finetuned\":\n",
    "            gold = df_results.loc[i, 'completion'].strip()\n",
    "            gold = gold[:gold.rfind(\"END\")].strip()\n",
    "        predicted = df_results.loc[i, 'GPT3 Completion'].strip()\n",
    "        # check if predicted or gold is multiple words\n",
    "        if \"-\" in predicted:\n",
    "            predicted = predicted.replace(\"-\", \" \")\n",
    "        try: \n",
    "            if len(predicted.split()) > 1:\n",
    "                predicted = matutils.unitvec(word_vectors.get_mean_vector(keys=predicted.split()))\n",
    "            else:\n",
    "                predicted = word_vectors.get_vector(predicted, norm=True)\n",
    "            if len(gold.split()) > 1:\n",
    "                #print(gold)\n",
    "                gold = matutils.unitvec(word_vectors.get_mean_vector(keys=gold.split()))\n",
    "            else:\n",
    "                gold = word_vectors.get_vector(gold, norm=True)\n",
    "            similarity = np.dot(predicted, gold)\n",
    "        except:\n",
    "            print(\"Error in computing embedding similarity for example: \", predicted, gold)\n",
    "            similarity = 0\n",
    "        df_results.loc[i, 'embedding_sim'] = similarity\n",
    "    mean = df_results['embedding_sim'].mean()\n",
    "    std = df_results['embedding_sim'].std()\n",
    "    return mean, std, df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_resource_for_similarity(resource, gold_standard, prediction):\n",
    "  response = requests.get(\"http://kgvec2go.org/rest/get-similarity/\"+resource+\"/\"+gold_standard+\"/\"+prediction)\n",
    "  if \"result\" in response.json():\n",
    "    sim = response.json()[\"result\"]\n",
    "  else: \n",
    "    sim = 0\n",
    "  \n",
    "  return sim\n",
    "\n",
    "def query_resource_related_concepts(resource, gold_standard):\n",
    "  concepts = []\n",
    "  response = requests.get(\"http://kgvec2go.org/rest/closest-concepts/\"+resource+\"/10/\"+gold_standard)\n",
    "  if \"result\" in response.json():\n",
    "    for concept in response.json()[\"result\"]: \n",
    "      concepts.append(str(concept[\"concept\"]))\n",
    "  else: \n",
    "    concepts =[] \n",
    "  \n",
    "  return concepts\n",
    "\n",
    "\n",
    "def tuple_KB_similarity(gold_standard, prediction): \n",
    "  similarities = []\n",
    "\n",
    "  similarities.extend([query_resource_for_similarity(\"alod\", gold_standard, prediction)] if query_resource_for_similarity(\"alod\", gold_standard, prediction) > 0 else [])\n",
    "  similarities.extend([query_resource_for_similarity(\"dbpedia\", gold_standard, prediction)] if query_resource_for_similarity(\"dbpedia\", gold_standard, prediction) > 0 else [])\n",
    "  similarities.extend([query_resource_for_similarity(\"wiktionary\", gold_standard, prediction)] if query_resource_for_similarity(\"wiktionary\", gold_standard, prediction) > 0 else [])\n",
    "  similarities.extend([query_resource_for_similarity(\"wordnet\", gold_standard, prediction)] if query_resource_for_similarity(\"wordnet\", gold_standard, prediction) > 0 else [])\n",
    "\n",
    "  if len(similarities) > 0: \n",
    "    average_sim = statistics.mean(similarities)\n",
    "  else: \n",
    "    average_sim = 0 \n",
    "\n",
    "  return average_sim\n",
    "\n",
    "def check_closest_concepts(gold_standard, prediction): \n",
    "  close = False\n",
    "  concepts = []\n",
    "\n",
    "  concepts.extend(query_resource_related_concepts(\"alod\", gold_standard) if len(query_resource_related_concepts(\"alod\", gold_standard)) > 0 else [])\n",
    "  concepts.extend(query_resource_related_concepts(\"dbpedia\", gold_standard) if len(query_resource_related_concepts(\"dbpedia\", gold_standard)) > 0 else [])\n",
    "  concepts.extend(query_resource_related_concepts(\"wiktionary\", gold_standard) if len(query_resource_related_concepts(\"wiktionary\", gold_standard)) > 0 else [])\n",
    "\n",
    "  for concept in concepts: \n",
    "    if prediction in concept: \n",
    "      close = True\n",
    "  \n",
    "  return close\n",
    "\n",
    "def compute_KB_similarity(df_results, task_type):\n",
    "    '''\n",
    "    df_results: dataframe containing the GPT3 completions\n",
    "    result_samples: number of samples to be evaluated\n",
    "    '''\n",
    "    for i in range(len(df_results)):\n",
    "        if task_type == \"Source\":\n",
    "            gold = df_results.loc[i, 'Source Domain']\n",
    "        elif task_type == \"Target\":\n",
    "            gold = df_results.loc[i, 'Target Domain']\n",
    "        elif task_type == \"Finetuned\":\n",
    "            gold = df_results.loc[i, 'completion'].strip()\n",
    "            # remove \"END\" token\n",
    "            gold = gold[:gold.rfind(\"END\")].strip()\n",
    "        predicted = df_results.loc[i, 'GPT3 Completion'].strip()\n",
    "        # use tuple_KB_similarity to compute the similarity between the gold and the predicted\n",
    "        if predicted == gold:\n",
    "          similarity = 1\n",
    "        else:\n",
    "          similarity = tuple_KB_similarity(gold, predicted)\n",
    "        df_results.loc[i, 'KB_similarity'] = similarity\n",
    "    mean = df_results['KB_similarity'].mean()\n",
    "    std = df_results['KB_similarity'].std()\n",
    "    return mean, std, df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df_results, task_type):\n",
    "    mean_em, std_em, df_results = compute_embedding_similarity(df_results, task_type)\n",
    "    print(\"Mean similarityc embeddings: \", mean_em)\n",
    "    print(\"Standard deviation embeddings: \", std_em)\n",
    "\n",
    "    mean_KB, std_KB, df_results = compute_KB_similarity(df_results, task_type)\n",
    "    print(\"Mean similarity KB: \", mean_KB)\n",
    "    print(\"Standard deviation KB: \", std_KB)\n",
    "    \n",
    "    return mean_em, std_em, mean_KB, std_KB, df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is currently specific to the task of predicting the source domain\n",
    "\n",
    "def get_GPT3_completions(train_indices, eval_set, temperature, model, result_samples, extra_def=False, reasoning=False, debug=False):\n",
    "    '''\n",
    "    train_indices: indices of the examples to be used for training\n",
    "    test: True if evaluation is on test set, False if evaluation is on validation set\n",
    "    temperature: temperature of the GPT3 model\n",
    "    model: GPT3 model to be used for evaluation\n",
    "    result_samples: number of samples to be evaluated\n",
    "    extra_def: True if extra definition is to be added to the beginning of the prompt\n",
    "    '''\n",
    "\n",
    "    if eval_set == \"test\":\n",
    "        prompts_test = list_of_source_prompts_test\n",
    "        completions_test = list_of_source_completions_test\n",
    "    elif eval_set == \"valid\":\n",
    "        prompts_test = list_of_source_prompts_valid\n",
    "        completions_test = list_of_source_completions_valid\n",
    "    elif eval_set == \"LCC\":\n",
    "        prompts_test = list_of_source_prompts_LCC\n",
    "        completions_test = list_of_source_completions_LCC\n",
    "    elif eval_set == \"LCC_es\":\n",
    "        prompts_test = list_of_source_prompts_LCC_es\n",
    "        completions_test = list_of_source_completions_LCC_es\n",
    "\n",
    "    if not reasoning:\n",
    "        prompts, completions = create_fewshot_prompts(prompts_train = list_of_source_prompts_train, completions_train = list_of_source_completions_train, \n",
    "                    prompts_test = prompts_test, completions_test = completions_test, train_indices=train_indices, extra_def=extra_def)\n",
    "    else:\n",
    "        prompts, completions = create_reasoning_prompts(prompts_test=prompts_test, completions_test=completions_test)\n",
    "   \n",
    "    GPT3_completions=[]\n",
    "    for i, p in enumerate(prompts[:result_samples]):\n",
    "        if debug:\n",
    "            print(\"Prompt\", i)\n",
    "            print(p)\n",
    "        else:\n",
    "            c = openai.Completion.create(\n",
    "                    model=model,\n",
    "                    prompt=p,\n",
    "                    max_tokens=100,\n",
    "                    temperature=temperature\n",
    "                )\n",
    "            GPT3_completions.append(c)\n",
    "            # wait to avoid rate limit\n",
    "            time.sleep(3)\n",
    "    \n",
    "    # append GPT3_completions to df_results \n",
    "    if debug == False:\n",
    "        if eval_set==\"test\":\n",
    "            df_results = test_df.copy().reset_index()\n",
    "        elif eval_set==\"valid\":\n",
    "            df_results = valid_df.copy().reset_index()\n",
    "        elif eval_set==\"LCC\":\n",
    "            df_results = LCC_df_300.copy().reset_index()\n",
    "        elif eval_set==\"LCC_es\":\n",
    "            df_results = LCC_es_df_110.copy().reset_index()\n",
    "        for i in range(len(GPT3_completions)):\n",
    "            df_results.loc[i, 'GPT3 Completion'] = GPT3_completions[i].choices[0].text\n",
    "        return df_results[:len(GPT3_completions)][[\"Target Domain\", \"Source Domain\",\"GPT3 Completion\", \"Example\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 0\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: I've lost all hope of a solution.\n",
      "Target Domain: hope\n",
      "Source Domain: possessions\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Even in backruptcy he managed to hang onto his car collection.\n",
      "Target Domain: possession\n",
      "Source Domain: holding\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: A tigress in bed.\n",
      "Target Domain: lust\n",
      "Source Domain: animal\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He's really high.\n",
      "Target Domain: euphoria\n",
      "Source Domain: up\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: We were made for each other.\n",
      "Target Domain: love\n",
      "Source Domain: part-whole\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Many theories sprang up out of the fertile soil of his discoveries.\n",
      "Target Domain: theories\n",
      "Source Domain: beings\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Her blood ran cold\n",
      "Target Domain: fear\n",
      "Source Domain: cold\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: the contagion of democratic ideas\n",
      "Target Domain: belief\n",
      "Source Domain: disease\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: She is made of tougher stuff.\n",
      "Target Domain: personality\n",
      "Source Domain: substance\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Things are at a standstill.\n",
      "Target Domain: progress\n",
      "Source Domain: motion\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: She took inventory of her beliefs.\n",
      "Target Domain: beliefs\n",
      "Source Domain: commodities\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: But he he said,  don't wash it I wanna wear it.\n",
      "Target Domain: washing\n",
      "Source Domain: not metaphoric\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He was wrecked.\n",
      "Target Domain: intoxication\n",
      "Source Domain:\n",
      "Prompt 1\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: I've lost all hope of a solution.\n",
      "Target Domain: hope\n",
      "Source Domain: possessions\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Even in backruptcy he managed to hang onto his car collection.\n",
      "Target Domain: possession\n",
      "Source Domain: holding\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: A tigress in bed.\n",
      "Target Domain: lust\n",
      "Source Domain: animal\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He's really high.\n",
      "Target Domain: euphoria\n",
      "Source Domain: up\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: We were made for each other.\n",
      "Target Domain: love\n",
      "Source Domain: part-whole\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Many theories sprang up out of the fertile soil of his discoveries.\n",
      "Target Domain: theories\n",
      "Source Domain: beings\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Her blood ran cold\n",
      "Target Domain: fear\n",
      "Source Domain: cold\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: the contagion of democratic ideas\n",
      "Target Domain: belief\n",
      "Source Domain: disease\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: She is made of tougher stuff.\n",
      "Target Domain: personality\n",
      "Source Domain: substance\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Things are at a standstill.\n",
      "Target Domain: progress\n",
      "Source Domain: motion\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: She took inventory of her beliefs.\n",
      "Target Domain: beliefs\n",
      "Source Domain: commodities\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: But he he said,  don't wash it I wanna wear it.\n",
      "Target Domain: washing\n",
      "Source Domain: not metaphoric\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He got thrashed.\n",
      "Target Domain: intoxication\n",
      "Source Domain:\n"
     ]
    }
   ],
   "source": [
    "best_indices=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, -1]\n",
    "get_GPT3_completions(train_indices=best_indices, eval_set=\"test\", temperature=0, model=\"davinci\", result_samples=2, extra_def=False, reasoning=False, debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_source_completions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters \n",
    "result_samples = 999 # 999 for all\n",
    "model = \"text-curie-001\" # or \"text-davinci-002\"\n",
    "train_indices = [\n",
    "    [0, -1], [3, -2], [6, -3],\n",
    "    [0, 10, 20, -1], [3, 13, 23, -2], [6, 16, 26, -3],\n",
    "    [0, 10, 20, 30, 40, -1], [3, 13, 23, 33, 43, -2], [6, 16, 26, 36, 46, -3],\n",
    "    [0, 10, 20, 30, 40, 50, 60, -1], [3, 13, 23, 33, 43, 53, 63, -2], [6, 16, 26, 36, 46, 56, 66, -3],\n",
    "    [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, -1], [3, 13, 23, 33, 43, 53, 63, 73, 83, 93, 103,-2], [6, 16, 26, 36, 46, 56, 66, 76, 86, 96, 106, -3]\n",
    "    ]\n",
    "#train_indices = [[0,15,30,45,-1]] # just for testing purposes\n",
    "group=\"gridsearch\" \n",
    "\n",
    "param_grid = {'temperature':[0], 'eval_set':[\"valid\"], 'extra_def':[False], 'model':[model], 'train_indices': train_indices} #\"text-curie-001\" for faster/cheaper model\n",
    "param_grid = list(ParameterGrid(param_grid))\n",
    "print(\"Number of parameter combinations: \", len(param_grid), \"\\n\")\n",
    "print(param_grid)\n",
    "scores_em = []\n",
    "scores_KB = []\n",
    "\n",
    "for i, params in enumerate(param_grid):\n",
    "    print(\"Parameter combination \", i+1, \"/\", len(param_grid))\n",
    "    if i+1 <= 11: # >11 before\n",
    "        print(\"Parameters: \", params, \"\\n\")\n",
    "        run_name=params[\"eval_set\"]+\"_\"+params['model'][5:]+\"_temp-\"+str(params['temperature'])+\"_\"+str(params['train_indices'])+\"_(\"+str(len(params['train_indices']))+\"-train-samples)\"+\"_def-\"+str(params['extra_def'])\n",
    "        # prompt \n",
    "        df_results = get_GPT3_completions(params[\"train_indices\"], eval_set=params[\"eval_set\"], temperature=params['temperature'], model=params['model'], result_samples=result_samples, extra_def=params['extra_def'])\n",
    "        # evaluate \n",
    "        mean_em, std_em, mean_KB, std_KB, df_results = evaluate(df_results, \"Source\")\n",
    "        run_name+=\"_embscore-\"+str(round(mean_em, 2))[2:]\n",
    "        run_name+=\"_KBscore-\"+str(round(mean_KB, 2))[2:]\n",
    "        scores_em.append(mean_em)\n",
    "        scores_KB.append(mean_KB)\n",
    "\n",
    "        config={\n",
    "            \"model\": params['model'],\n",
    "            \"temperature\": params['temperature'],\n",
    "            \"train_indices\": params['train_indices'],\n",
    "            \"train_samples\": len(params['train_indices']),\n",
    "            \"extra_def\": params['extra_def'],\n",
    "            \"eval_set\": params['eval_set'],\n",
    "        }\n",
    "\n",
    "\n",
    "        with wandb.init(project=\"Metaphors\", config=config, group=group):\n",
    "            wandb.log({\"mean_em\": mean_em, \"std_em\": std_em, \"mean_KB\": mean_KB, \"std_KB\": std_KB})\n",
    "\n",
    "        df_results.to_csv(\"Validation Results/Source Completion/Few Shot/\"+run_name+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_samples=[2,4,6,8,12]\n",
    "scores_em_davinci = [[], [], [], [], []]\n",
    "scores_KB_davinci = [[], [], [], [], []]\n",
    "scores_em_curie = [[], [], [], [], []]\n",
    "scores_KB_curie = [[], [], [], [], []]\n",
    "c1=\"darkblue\"\n",
    "c2=\"lightblue\"\n",
    "c3=\"darkred\"\n",
    "c4=\"red\"\n",
    "\n",
    "for run in wandb.Api().runs(\"YOUR_USERNAME/YOUR_PROJECT\"): # replace with your username and project name\n",
    "    if run.group == \"gridsearch\":\n",
    "        amount_samples=run.config[\"train_samples\"]\n",
    "        if run.config[\"model\"]==\"text-davinci-002\":\n",
    "            scores_em_davinci[train_samples.index(amount_samples)].append(run.summary[\"mean_em\"])\n",
    "            scores_KB_davinci[train_samples.index(amount_samples)].append(run.summary[\"mean_KB\"])\n",
    "        elif run.config[\"model\"]==\"text-curie-001\":\n",
    "            scores_em_curie[train_samples.index(amount_samples)].append(run.summary[\"mean_em\"])\n",
    "            scores_KB_curie[train_samples.index(amount_samples)].append(run.summary[\"mean_KB\"])\n",
    "# plot averaged score + SD for each number of training samples\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.errorbar([2,4,6,8,12], [np.mean(scores_KB_davinci[0]), np.mean(scores_KB_davinci[1]), np.mean(scores_KB_davinci[2]), np.mean(scores_KB_davinci[3]), np.mean(scores_KB_davinci[4])], yerr=[np.std(scores_KB_davinci[0], ddof=1), np.std(scores_KB_davinci[1], ddof=1), np.std(scores_KB_davinci[2], ddof=1), np.std(scores_KB_davinci[3], ddof=1), np.std(scores_KB_davinci[4], ddof=1)], fmt='o', label=\"KB score, davinci\", color=c1)\n",
    "plt.errorbar([2,4,6,8,12], [np.mean(scores_em_davinci[0]), np.mean(scores_em_davinci[1]), np.mean(scores_em_davinci[2]), np.mean(scores_em_davinci[3]), np.mean(scores_em_davinci[4])], yerr=[np.std(scores_em_davinci[0], ddof=1), np.std(scores_em_davinci[1], ddof=1), np.std(scores_em_davinci[2], ddof=1), np.std(scores_em_davinci[3], ddof=1), np.std(scores_em_davinci[4], ddof=1)], fmt='o', label=\"Embedding score, davinci\", color=c2)\n",
    "plt.errorbar([2,4,6,8,12], [np.mean(scores_KB_curie[0]), np.mean(scores_KB_curie[1]), np.mean(scores_KB_curie[2]), np.mean(scores_KB_curie[3]), np.mean(scores_KB_curie[4])], yerr=[np.std(scores_KB_curie[0], ddof=1), np.std(scores_KB_curie[1], ddof=1), np.std(scores_KB_curie[2], ddof=1), np.std(scores_KB_curie[3], ddof=1), np.std(scores_KB_curie[4], ddof=1)], fmt='s', label=\"KB score, curie\", color=c3)\n",
    "plt.errorbar([2,4,6,8,12], [np.mean(scores_em_curie[0]), np.mean(scores_em_curie[1]), np.mean(scores_em_curie[2]), np.mean(scores_em_curie[3]), np.mean(scores_em_curie[4])], yerr=[np.std(scores_em_curie[0], ddof=1), np.std(scores_em_curie[1], ddof=1), np.std(scores_em_curie[2], ddof=1), np.std(scores_em_curie[3], ddof=1), np.std(scores_em_curie[4], ddof=1)], fmt='s', label=\"Embedding score, curie\", color=c4)\n",
    "# make standard deviation thicker\n",
    "plt.fill_between([2,4,6,8,12], [np.mean(scores_KB_davinci[0])-np.std(scores_KB_davinci[0], ddof=1), np.mean(scores_KB_davinci[1])-np.std(scores_KB_davinci[1], ddof=1), np.mean(scores_KB_davinci[2])-np.std(scores_KB_davinci[2], ddof=1), np.mean(scores_KB_davinci[3])-np.std(scores_KB_davinci[3], ddof=1), np.mean(scores_KB_davinci[4])-np.std(scores_KB_davinci[4], ddof=1)], [np.mean(scores_KB_davinci[0])+np.std(scores_KB_davinci[0], ddof=1), np.mean(scores_KB_davinci[1])+np.std(scores_KB_davinci[1], ddof=1), np.mean(scores_KB_davinci[2])+np.std(scores_KB_davinci[2], ddof=1), np.mean(scores_KB_davinci[3])+np.std(scores_KB_davinci[3], ddof=1), np.mean(scores_KB_davinci[4])+np.std(scores_KB_davinci[4], ddof=1)], alpha=0.2, color=c1)\n",
    "plt.fill_between([2,4,6,8,12], [np.mean(scores_em_davinci[0])-np.std(scores_em_davinci[0], ddof=1), np.mean(scores_em_davinci[1])-np.std(scores_em_davinci[1], ddof=1), np.mean(scores_em_davinci[2])-np.std(scores_em_davinci[2], ddof=1), np.mean(scores_em_davinci[3])-np.std(scores_em_davinci[3], ddof=1), np.mean(scores_em_davinci[4])-np.std(scores_em_davinci[4], ddof=1)], [np.mean(scores_em_davinci[0])+np.std(scores_em_davinci[0], ddof=1), np.mean(scores_em_davinci[1])+np.std(scores_em_davinci[1], ddof=1), np.mean(scores_em_davinci[2])+np.std(scores_em_davinci[2], ddof=1), np.mean(scores_em_davinci[3])+np.std(scores_em_davinci[3], ddof=1), np.mean(scores_em_davinci[4])+np.std(scores_em_davinci[4], ddof=1)], alpha=0.2, color=c2)\n",
    "plt.fill_between([2,4,6,8,12], [np.mean(scores_KB_curie[0])-np.std(scores_KB_curie[0], ddof=1), np.mean(scores_KB_curie[1])-np.std(scores_KB_curie[1], ddof=1), np.mean(scores_KB_curie[2])-np.std(scores_KB_curie[2], ddof=1), np.mean(scores_KB_curie[3])-np.std(scores_KB_curie[3], ddof=1), np.mean(scores_KB_curie[4])-np.std(scores_KB_curie[4], ddof=1)], [np.mean(scores_KB_curie[0])+np.std(scores_KB_curie[0], ddof=1), np.mean(scores_KB_curie[1])+np.std(scores_KB_curie[1], ddof=1), np.mean(scores_KB_curie[2])+np.std(scores_KB_curie[2], ddof=1), np.mean(scores_KB_curie[3])+np.std(scores_KB_curie[3], ddof=1), np.mean(scores_KB_curie[4])+np.std(scores_KB_curie[4], ddof=1)], alpha=0.2, color=c3)\n",
    "plt.fill_between([2,4,6,8,12], [np.mean(scores_em_curie[0])-np.std(scores_em_curie[0], ddof=1), np.mean(scores_em_curie[1])-np.std(scores_em_curie[1], ddof=1), np.mean(scores_em_curie[2])-np.std(scores_em_curie[2], ddof=1), np.mean(scores_em_curie[3])-np.std(scores_em_curie[3], ddof=1), np.mean(scores_em_curie[4])-np.std(scores_em_curie[4], ddof=1)], [np.mean(scores_em_curie[0])+np.std(scores_em_curie[0], ddof=1), np.mean(scores_em_curie[1])+np.std(scores_em_curie[1], ddof=1), np.mean(scores_em_curie[2])+np.std(scores_em_curie[2], ddof=1), np.mean(scores_em_curie[3])+np.std(scores_em_curie[3], ddof=1), np.mean(scores_em_curie[4])+np.std(scores_em_curie[4], ddof=1)], alpha=0.2, color=c4)\n",
    "plt.xlabel(\"Number of Few-shot Training Samples\")\n",
    "plt.ylabel(\"Score\")\n",
    "# connect error bars with lines\n",
    "plt.plot([2,4,6,8,12], [np.mean(scores_KB_davinci[0]), np.mean(scores_KB_davinci[1]), np.mean(scores_KB_davinci[2]), np.mean(scores_KB_davinci[3]), np.mean(scores_KB_davinci[4])], 'o-', color=c1)\n",
    "plt.plot([2,4,6,8,12], [np.mean(scores_em_davinci[0]), np.mean(scores_em_davinci[1]), np.mean(scores_em_davinci[2]), np.mean(scores_em_davinci[3]), np.mean(scores_em_davinci[4])], 'o-', color=c2)\n",
    "plt.plot([2,4,6,8,12], [np.mean(scores_KB_curie[0]), np.mean(scores_KB_curie[1]), np.mean(scores_KB_curie[2]), np.mean(scores_KB_curie[3]), np.mean(scores_KB_curie[4])], 's-', color=c3)\n",
    "plt.plot([2,4,6,8,12], [np.mean(scores_em_curie[0]), np.mean(scores_em_curie[1]), np.mean(scores_em_curie[2]), np.mean(scores_em_curie[3]), np.mean(scores_em_curie[4])], 's-', color=c4)\n",
    "\n",
    "\n",
    "\n",
    "# make star for single best score and set to foreground\n",
    "plt.plot([12], 0.5531443181819444, '*', color=c1, markersize=25, label=\"Highest KB score\")\n",
    "plt.plot([12], 0.5047760359942913, '*', color=c2, markersize=25, label=\"Highest embedding score\", zorder=10)\n",
    "plt.legend()\n",
    "plt.grid(color='lightgray', linestyle='-', linewidth=0.5)\n",
    "# move legend outside of plot\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left', borderaxespad=0., fontsize=13, frameon=False, handletextpad=0.4, labelspacing=1.8)\n",
    "# increase spacing of legend\n",
    "# make y axis end at 0.6\n",
    "plt.ylim(0.2, 0.575)\n",
    "# make x axis end at 12\n",
    "plt.xlim(2, 12.1)\n",
    "# set font to Times New Roman\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 16\n",
    "# save as eps\n",
    "plt.savefig('Images/scores.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config:  {'model': 'text-davinci-002', 'eval_set': 'valid', 'extra_def': False, 'temperature': 0, 'train_indices': [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, -1], 'train_samples': 12}\n"
     ]
    }
   ],
   "source": [
    "# load scores from wandb\n",
    "run_configs=[]\n",
    "scores_em = []\n",
    "scores_KB = []\n",
    "for run in wandb.Api().runs(\"YOUR_USERNAME/YOUR_PROJECT\"): # replace with your username and project name\n",
    "    scores_em.append(run.summary[\"mean_em\"])\n",
    "    scores_KB.append(run.summary[\"mean_KB\"])\n",
    "    run_configs.append(run.config)\n",
    "# return config with highest average of em and KB scores\n",
    "best_config = run_configs[np.argmax(np.array(scores_em)+np.array(scores_KB))]\n",
    "print(\"Best config: \", best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate completions on test set with best config from validation\n",
    "df_test_results = get_GPT3_completions(best_config[\"train_indices\"], eval_set=\"test\", temperature=best_config['temperature'], model=best_config['model'], result_samples=999, extra_def=best_config['extra_def'])\n",
    "df_LCC_results = get_GPT3_completions(best_config[\"train_indices\"], eval_set=\"LCC\", temperature=best_config['temperature'], model=best_config['model'], result_samples=999, extra_def=best_config['extra_def'])\n",
    "df_LCC_results_es = get_GPT3_completions(best_config[\"train_indices\"], eval_set=\"LCC_es\", temperature=best_config['temperature'], model=best_config['model'], result_samples=999, extra_def=best_config['extra_def'])\n",
    "# evaluate\n",
    "mean_em, std_em, mean_KB, std_KB, df_test_results = evaluate(df_test_results)\n",
    "print(\"Test set performance: \", str(mean_em)+\"(+-\"+str(std_em)+\")\", str(mean_KB)+\"(+-\"+str(std_KB)+\")\")\n",
    "mean_em, std_em, mean_KB, std_KB, df_LCC_results = evaluate(df_LCC_results)\n",
    "print(\"LCC set performance: \", str(mean_em)+\"(+-\"+str(std_em)+\")\", str(mean_KB)+\"(+-\"+str(std_KB)+\")\")\n",
    "mean_em, std_em, mean_KB, std_KB, df_LCC_results_es = evaluate(df_LCC_results_es)\n",
    "print(\"LCC set performance: \", str(mean_em)+\"(+-\"+str(std_em)+\")\", str(mean_KB)+\"(+-\"+str(std_KB)+\")\")\n",
    "# save results to csv\n",
    "df_test_results.to_csv(\"Test Results/Source Completion/Few Shot/best_config_test.csv\")\n",
    "df_LCC_results.to_csv(\"Test Results/Source Completion/Few Shot/best_config_LCC.csv\")\n",
    "df_LCC_results_es.to_csv(\"Test Results/Source Completion/Few Shot/best_config_LCC_es.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Domain</th>\n",
       "      <th>Source Domain</th>\n",
       "      <th>GPT3 Completion</th>\n",
       "      <th>Example</th>\n",
       "      <th>embedding_sim</th>\n",
       "      <th>KB_similarity</th>\n",
       "      <th>Annotator 1 (L)</th>\n",
       "      <th>Comments (L)</th>\n",
       "      <th>Annotator 2 (D)</th>\n",
       "      <th>Comments (D)</th>\n",
       "      <th>Final Annotation</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Error Code</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intoxication</td>\n",
       "      <td>destruction</td>\n",
       "      <td>shipwreck</td>\n",
       "      <td>He was wrecked.</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1</td>\n",
       "      <td>unsure (too specific)</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intoxication</td>\n",
       "      <td>destruction</td>\n",
       "      <td>violence</td>\n",
       "      <td>He got thrashed.</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amount</td>\n",
       "      <td>size</td>\n",
       "      <td>breakable object</td>\n",
       "      <td>Can you break a twenty?</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amount</td>\n",
       "      <td>size</td>\n",
       "      <td>size</td>\n",
       "      <td>I'm not a big eater.</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beliefs</td>\n",
       "      <td>plants</td>\n",
       "      <td>seeds</td>\n",
       "      <td>I planted the belief in his mind.</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target Domain Source Domain   GPT3 Completion  \\\n",
       "0  intoxication   destruction         shipwreck   \n",
       "1  intoxication   destruction          violence   \n",
       "2        amount          size  breakable object   \n",
       "3        amount          size              size   \n",
       "4       beliefs        plants             seeds   \n",
       "\n",
       "                             Example  embedding_sim  KB_similarity  \\\n",
       "0                    He was wrecked.           0.10           0.35   \n",
       "1                   He got thrashed.           0.37           0.33   \n",
       "2            Can you break a twenty?           0.16           0.31   \n",
       "3               I'm not a big eater.           1.00           1.00   \n",
       "4  I planted the belief in his mind.           0.40           0.64   \n",
       "\n",
       "   Annotator 1 (L)           Comments (L)  Annotator 2 (D) Comments (D)  \\\n",
       "0                1  unsure (too specific)                1          NaN   \n",
       "1                1                    NaN                1          NaN   \n",
       "2                1                    NaN                1          NaN   \n",
       "3                1                    NaN                1          NaN   \n",
       "4                1                    NaN                1          NaN   \n",
       "\n",
       "   Final Annotation  Comments Error Code Unnamed: 14  \n",
       "0                 1       NaN        NaN         NaN  \n",
       "1                 1       NaN        NaN         NaN  \n",
       "2                 1       NaN        NaN         NaN  \n",
       "3                 1       NaN        NaN         NaN  \n",
       "4                 1       NaN        NaN         NaN  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_test_df = pd.read_csv(\"Test Results/Source Completion/Few Shot/MetaphorList_annotated_test.csv\", index_col=0)\n",
    "annotated_LCC_df = pd.read_csv(\"Test Results/Source Completion/Few Shot/LCC-EN_annotated_test.csv\", index_col=0 )\n",
    "annotated_test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split annotated_test_df into two dataframes, one for samples where source domain is non metaphoric and the others\n",
    "annotated_test_df_non_metaphoric = annotated_test_df[annotated_test_df[\"Source Domain\"] == \"not metaphoric\"]\n",
    "annotated_test_df_metaphoric = annotated_test_df[annotated_test_df[\"Source Domain\"] != \"not metaphoric\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's kappa for non metaphoric samples:  0.8901734104046243\n",
      "Cohen's kappa for Metaphor List samples:  0.5487752470992694\n",
      "Cohen's kappa for LCC samples:  0.4458952423833108\n",
      "\n",
      "Agreement in percent for non metaphoric samples:  0.9473684210526315\n",
      "Agreement in percent for Metaphor List samples:  0.8755555555555555\n",
      "Agreement in percent for LCC samples:  0.7253521126760564\n",
      "\n",
      "Average agreement in percent:  0.8494253630947478\n",
      "Average Cohen's kappa:  0.6282812999624015\n",
      "\n",
      "Weighted average agreement in percent:  0.7973484848484849\n",
      "Weighted average Cohen's kappa:  0.5057234360452344\n"
     ]
    }
   ],
   "source": [
    "# compute cohen's kappa between Annotation 1 and Annotation 2\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "ck_non=cohen_kappa_score(annotated_test_df_non_metaphoric[\"Annotator 1 (L)\"], annotated_test_df_non_metaphoric[\"Annotator 2 (D)\"])\n",
    "print(\"Cohen's kappa for non metaphoric samples: \", ck_non)\n",
    "ck_met=cohen_kappa_score(annotated_test_df_metaphoric[\"Annotator 1 (L)\"], annotated_test_df_metaphoric[\"Annotator 2 (D)\"])\n",
    "print(\"Cohen's kappa for Metaphor List samples: \", ck_met)\n",
    "ck_LCC=cohen_kappa_score(annotated_LCC_df[\"Annotator 1 (L)\"], annotated_LCC_df[\"Annotator 2 (D)\"])\n",
    "print(\"Cohen's kappa for LCC samples: \", ck_LCC)\n",
    "print()\n",
    "\n",
    "# compute agreement as percentage for non metaphoric samples\n",
    "agreement_non = np.sum(annotated_test_df_non_metaphoric[\"Annotator 1 (L)\"] == annotated_test_df_non_metaphoric[\"Annotator 2 (D)\"])/len(annotated_test_df_non_metaphoric)\n",
    "print(\"Agreement in percent for non metaphoric samples: \", agreement_non)\n",
    "# compute agreement as percentage for metaphor list samples\n",
    "agreement_met = np.sum(annotated_test_df_metaphoric[\"Annotator 1 (L)\"] == annotated_test_df_metaphoric[\"Annotator 2 (D)\"])/len(annotated_test_df_metaphoric)\n",
    "print(\"Agreement in percent for Metaphor List samples: \", agreement_met)\n",
    "# compute agreement as percentage for LCC samples\n",
    "agreement_LCC = np.sum(annotated_LCC_df[\"Annotator 1 (L)\"] == annotated_LCC_df[\"Annotator 2 (D)\"])/len(annotated_LCC_df)\n",
    "print(\"Agreement in percent for LCC samples: \", agreement_LCC)\n",
    "\n",
    "# average agreement for all samples\n",
    "print()\n",
    "print(\"Average agreement in percent: \", (agreement_non+agreement_met+agreement_LCC)/3)\n",
    "print(\"Average Cohen's kappa: \", (ck_non+ck_met+ck_LCC)/3)\n",
    "# weighted average agreement for all samples\n",
    "print()\n",
    "print(\"Weighted average agreement in percent: \", (agreement_non*len(annotated_test_df_non_metaphoric)+agreement_met*len(annotated_test_df_metaphoric)+agreement_LCC*len(annotated_LCC_df))/(len(annotated_test_df_non_metaphoric)+len(annotated_test_df_metaphoric)+len(annotated_LCC_df)))\n",
    "print(\"Weighted average Cohen's kappa: \", (ck_non*len(annotated_test_df_non_metaphoric)+ck_met*len(annotated_test_df_metaphoric)+ck_LCC*len(annotated_LCC_df))/(len(annotated_test_df_non_metaphoric)+len(annotated_test_df_metaphoric)+len(annotated_LCC_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove samples where annotators \"Final annotation\" == 2 \n",
    "annotated_test_df_non_metaphoric = annotated_test_df_non_metaphoric[annotated_test_df_non_metaphoric[\"Final Annotation\"] != 2]\n",
    "annotated_test_df_metaphoric = annotated_test_df_metaphoric[annotated_test_df_metaphoric[\"Final Annotation\"] != 2]\n",
    "annotated_LCC_df = annotated_LCC_df[annotated_LCC_df[\"Final Annotation\"] != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy based on final annotation non metaphoric:  0.42105263157894735\n",
      "Accuracy based on final annotation Metaphor List:  0.8133333333333334\n",
      "Accuracy based on final annotation LCC:  0.5373665480427047\n"
     ]
    }
   ],
   "source": [
    "# print accuracy based on final annotation\n",
    "print(\"Accuracy based on final annotation non metaphoric: \", sum(annotated_test_df_non_metaphoric[\"Final Annotation\"])/len(annotated_test_df_non_metaphoric))\n",
    "print(\"Accuracy based on final annotation Metaphor List: \", sum(annotated_test_df_metaphoric[\"Final Annotation\"])/len(annotated_test_df_metaphoric))\n",
    "print(\"Accuracy based on final annotation LCC: \", sum(annotated_LCC_df[\"Final Annotation\"])/len(annotated_LCC_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation KB non metaphoric:  SpearmanrResult(correlation=0.8955910525085282, pvalue=2.202100379409556e-07)\n",
      "Spearman correlation KB Metaphor List:  SpearmanrResult(correlation=0.34432716202421004, pvalue=1.1639251248950027e-07)\n",
      "Spearman correlation EM non metaphoric:  SpearmanrResult(correlation=0.8802224000709448, pvalue=6.703159561855441e-07)\n",
      "Spearman correlation EM Metaphor List:  SpearmanrResult(correlation=0.3864533413655767, pvalue=1.9827552286916033e-09)\n",
      "Spearman correlation KB all:  SpearmanrResult(correlation=0.4319537445637061, pvalue=1.6388503310107196e-12)\n",
      "Spearman correlation EM all:  SpearmanrResult(correlation=0.40255186337112375, pvalue=6.390186126270552e-11)\n"
     ]
    }
   ],
   "source": [
    "# compute spearman correlation between KB score and final annotation\n",
    "from scipy.stats import spearmanr\n",
    "sp_non_met=spearmanr(annotated_test_df_non_metaphoric[\"KB_similarity\"], annotated_test_df_non_metaphoric[\"Final Annotation\"])\n",
    "sp_MetList=spearmanr(annotated_test_df_metaphoric[\"KB_similarity\"], annotated_test_df_metaphoric[\"Final Annotation\"])\n",
    "print(\"Spearman correlation KB non metaphoric: \", sp_non_met)\n",
    "print(\"Spearman correlation KB Metaphor List: \", sp_MetList)\n",
    "# same for embedding_sim\n",
    "sp_non_met=spearmanr(annotated_test_df_non_metaphoric[\"embedding_sim\"], annotated_test_df_non_metaphoric[\"Final Annotation\"])\n",
    "sp_MetList=spearmanr(annotated_test_df_metaphoric[\"embedding_sim\"], annotated_test_df_metaphoric[\"Final Annotation\"])\n",
    "print(\"Spearman correlation EM non metaphoric: \", sp_non_met)\n",
    "print(\"Spearman correlation EM Metaphor List: \", sp_MetList)\n",
    "\n",
    "# merge annotated_test_df_non_metaphoric and annotated_test_df_metaphoric and compute spearman correlation between KB score and final annotation\n",
    "annotated_test_df_all = pd.concat([annotated_test_df_non_metaphoric, annotated_test_df_metaphoric])\n",
    "sp_all=spearmanr(annotated_test_df_all[\"KB_similarity\"], annotated_test_df_all[\"Final Annotation\"])\n",
    "print(\"Spearman correlation KB all: \", sp_all)\n",
    "# same for embedding_sim\n",
    "sp_all=spearmanr(annotated_test_df_all[\"embedding_sim\"], annotated_test_df_all[\"Final Annotation\"])\n",
    "print(\"Spearman correlation EM all: \", sp_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_finetuning_dataset(raw_prompts, raw_completions, name):\n",
    "    prompts = []\n",
    "    completions = []\n",
    "    for i in range(len(raw_prompts)):\n",
    "        prompts.append(raw_prompts[i][71:])\n",
    "        completions.append(\" \"+raw_completions[i]+\" END\")\n",
    "    df = pd.DataFrame({'prompt': prompts, 'completion': completions})\n",
    "    df.to_csv(name, index=False)\n",
    "\n",
    "create_finetuning_dataset(list_of_source_prompts_train, list_of_source_completions_train, \"Finetuning Data/source-finetuning-train.csv\")\n",
    "create_finetuning_dataset(list_of_source_prompts_test, list_of_source_completions_test, \"Finetuning Data/source-finetuning-test.csv\")\n",
    "create_finetuning_dataset(list_of_source_prompts_valid, list_of_source_completions_valid, \"Finetuning Data/source-finetuning-valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have only one train example from list_of_source_completions_train per unique completion\n",
    "unique_completions = []\n",
    "unique_prompts = []\n",
    "for i in range(len(list_of_source_completions_train)):\n",
    "    if list_of_source_completions_train[i] not in unique_completions:\n",
    "        unique_completions.append(list_of_source_completions_train[i])\n",
    "        unique_prompts.append(list_of_source_prompts_train[i])\n",
    "create_finetuning_dataset(unique_prompts, unique_completions, \"Finetuning Data/source-finetuning-train-unique.csv\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 132\n"
     ]
    }
   ],
   "source": [
    "print(len(unique_prompts), len(list_of_source_completions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the required json files for finetuning run the following command in the console:\n",
    "\n",
    "    openai tools fine_tunes.prepare_data -f <LOCAL_FILE.csv>\n",
    "\n",
    "Afterwards create finetuned model with:\n",
    "\n",
    "    export OPENAI_API_KEY=<YOUR_API_KEY>\n",
    "\n",
    "    openai api fine_tunes.create -t <TRAIN_FILE_ID_OR_PATH> -m davinci --suffix \"<name>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GPT3_completions_finetune(test, temperature, model, result_samples):\n",
    "    if test:\n",
    "        data=pd.read_csv(\"Finetuning Data/source-finetuning-test.csv\")\n",
    "    else:\n",
    "        data=pd.read_csv(\"Finetuning Data/source-finetuning-valid.csv\")\n",
    "    \n",
    "    prompts = data['prompt']\n",
    "    completions = data['completion']\n",
    "\n",
    "    GPT3_completions=[]\n",
    "    for p in prompts[:result_samples]:\n",
    "        c = openai.Completion.create(\n",
    "                model=model,\n",
    "                prompt=p,\n",
    "                max_tokens=14,\n",
    "                temperature=temperature,\n",
    "                stop=[\" END\"]\n",
    "\n",
    "            )\n",
    "        GPT3_completions.append(c)\n",
    "        # wait to avoid rate limit\n",
    "        time.sleep(3)\n",
    "\n",
    "    df_results = data.copy().reset_index()\n",
    "\n",
    "    # append GPT3_completions to df_results [trainings_units:len(GPT3_completions)]\n",
    "    for i in range(len(GPT3_completions)):\n",
    "        gpt3_completion = GPT3_completions[i].choices[0].text\n",
    "        # strip everything after the first newline\n",
    "        #gpt3_completion = gpt3_completion.split(\"\\n\")[0]\n",
    "        df_results.loc[i, 'GPT3 Completion'] = gpt3_completion\n",
    "    return df_results[:len(GPT3_completions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"YOUR_FINETUNED_MODEL_NAME\" # you will receive this name after finetuning as described above \n",
    "\n",
    "temperature=0\n",
    "result_samples=999\n",
    "test=False\n",
    "if \"unique\" in model:\n",
    "    train_samples = 34\n",
    "else:\n",
    "    train_samples = 132\n",
    "\n",
    "run_name=\"Finetuned_temp-\"+str(temperature)+model\n",
    "if test:\n",
    "    run_name=run_name+\"_test\"\n",
    "else:\n",
    "    run_name=run_name+\"_valid\"\n",
    "\n",
    "\n",
    "df_results = get_GPT3_completions_finetune(test, temperature, model, result_samples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# evaluate\n",
    "mean_em, std_em, mean_KB, std_KB, df_results = evaluate(df_results, \"Finetuned\")\n",
    "print(\"Performance: \", str(mean_em)+\"(+-\"+str(std_em)+\")\", str(mean_KB)+\"(+-\"+str(std_KB)+\")\")\n",
    "run_name=run_name+\"_em-\"+str(round(mean_em,3))+\"_KB-\"+str(round(mean_KB,3))\n",
    "\n",
    "config={\n",
    "    \"model\": model,\n",
    "    \"temperature\": temperature,\n",
    "    \"train_indices\": \"finetuned\",\n",
    "    \"train_samples\": train_samples,\n",
    "    \"extra_def\": False,\n",
    "    \"eval_set\": \"valid\",\n",
    "}\n",
    "\n",
    "run_name.replace(\"/\", \"-\")\n",
    "\n",
    "with wandb.init(project=\"Metaphors\", config=config, group=\"finetuned\"):\n",
    "    wandb.log({\"mean_em\": mean_em, \"std_em\": std_em, \"mean_KB\": mean_KB, \"std_KB\": std_KB})\n",
    "\n",
    "df_results.to_csv(\"Validation Results/Source Completion/Finetuned/\"+run_name+\".csv\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique source domains\n",
      "unique: 78\n",
      "full: 50\n",
      "best: 74\n",
      "overlap with train\n",
      "unique: 13\n",
      "full: 18\n",
      "best: 7\n"
     ]
    }
   ],
   "source": [
    "# look at diversity of completions\n",
    "print(\"unique source domains\")\n",
    "df_results_finetuneunique = pd.read_csv(\"Validation Results/Source Completion/Finetuned/Finetuned_temp-0davinci-ft-personal-unique34samples-2022-10-30-12-23-49_valid_em-0.303_KB-0.386.csv\")\n",
    "print(\"unique:\", len(df_results_finetuneunique[\"GPT3 Completion\"].unique()))\n",
    "df_results_finetunefull = pd.read_csv(\"Validation Results/Source Completion/Finetuned/Finetuned_temp-0davinci-ft-personal-fulltrain-2022-11-03-15-21-24_valid_em-0.413_KB-0.513.csv\")\n",
    "print(\"full:\", len(df_results_finetunefull[\"GPT3 Completion\"].unique()))\n",
    "df_results_best = pd.read_csv(\"Validation Results/Source Completion/Few Shot/valid_davinci-002_temp-0_[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, -1]_(12-train-samples)_def-False_embscore-5_KBscore-55.csv\")\n",
    "print(\"best:\", len(df_results_best[\"GPT3 Completion\"].unique()))\n",
    "# overlap between GPT3 completions of finetuned models and train_df \"Source Domain\"\n",
    "predicted_domains_full = set(df_results_finetunefull[\"GPT3 Completion\"])\n",
    "predicted_domains_unique = set(df_results_finetuneunique[\"GPT3 Completion\"])\n",
    "predicted_domains_best = set(df_results_best[\"GPT3 Completion\"])\n",
    "# remove END token\n",
    "predicted_domains_full = set([x.replace(\" END\", \"\").strip() for x in predicted_domains_full])\n",
    "predicted_domains_unique = set([x.replace(\" END\", \"\").strip() for x in predicted_domains_unique])\n",
    "predicted_domains_best = set([x.replace(\" END\", \"\").strip() for x in predicted_domains_best])\n",
    "print(\"overlap with train\")\n",
    "print(\"unique:\", len(predicted_domains_unique.intersection(set(train_df[\"Source Domain\"]))))\n",
    "print(\"full:\", len(predicted_domains_full.intersection(set(train_df[\"Source Domain\"]))))\n",
    "print(\"best:\", len(predicted_domains_best.intersection(set(train_df[\"Source Domain\"]))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'advantage',\n",
       " 'adversary',\n",
       " 'age',\n",
       " 'alive',\n",
       " 'animal',\n",
       " 'balloon',\n",
       " 'beings',\n",
       " 'belief',\n",
       " 'bottom',\n",
       " 'center',\n",
       " 'clarity',\n",
       " 'commodities',\n",
       " 'competition',\n",
       " 'container',\n",
       " 'darkness',\n",
       " 'defeat',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'existence',\n",
       " 'flow',\n",
       " 'force',\n",
       " 'heat',\n",
       " 'injury',\n",
       " 'interpretation',\n",
       " 'length',\n",
       " 'light',\n",
       " 'line',\n",
       " 'machines',\n",
       " 'money',\n",
       " 'motion',\n",
       " 'not metaphoric',\n",
       " 'palm',\n",
       " 'part-whole',\n",
       " 'path',\n",
       " 'possessions',\n",
       " 'predators',\n",
       " 'pull',\n",
       " 'scale',\n",
       " 'sight',\n",
       " 'size',\n",
       " 'space',\n",
       " 'speech',\n",
       " 'stability',\n",
       " 'substance',\n",
       " 'sum',\n",
       " 'thirst',\n",
       " 'time',\n",
       " 'weapons',\n",
       " 'weight',\n",
       " 'wheel'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_domains_full"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Application Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset the-reddit-covid-dataset/posts to /Users/lennartwachowiak/.cache/huggingface/datasets/SocialGrep___the-reddit-covid-dataset/posts/1.0.0/35698a78e6ebe9f3da4d0d354139c89d8097b4498816cab987639ad00dbe4a92...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 580M/580M [01:01<00:00, 9.36MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [01:02<00:00, 62.77s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:08<00:00,  8.89s/it]\n",
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset the-reddit-covid-dataset downloaded and prepared to /Users/lennartwachowiak/.cache/huggingface/datasets/SocialGrep___the-reddit-covid-dataset/posts/1.0.0/35698a78e6ebe9f3da4d0d354139c89d8097b4498816cab987639ad00dbe4a92. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  6.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "text_dataset = load_dataset(\"SocialGrep/the-reddit-covid-dataset\", \"posts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_to_analyse=[]\n",
    "for sentence in text_dataset[\"train\"][\"title\"][0:10000]:\n",
    "    if \"restriction\" in sentence:\n",
    "        sentences_to_analyse.append(sentence)\n",
    "        #print(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates from sentences_to_analyse\n",
    "sentences_to_analyse = list(set(sentences_to_analyse))\n",
    "print(len(sentences_to_analyse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_long_prompt_new_text(list_of_prompts, list_of_completions, start_index, end_index, query_text, query_target):\n",
    "    prompt=\"\"\n",
    "    for j in range(start_index, end_index):\n",
    "        prompt+=list_of_prompts[j]+list_of_completions[j]+\"\\n\"\n",
    "    prompt+=\"Extract the conceptual metaphor from the following sentence:\\nSentence: \"\n",
    "    prompt+=query_text\n",
    "    prompt+=\"\\nTarget Domain: \"+query_target\n",
    "    prompt+=\"\\nSource Domain:\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_prompts = []\n",
    "for s in sentences_to_analyse:\n",
    "    analysis_prompts.append(create_long_prompt_new_text(list_of_source_prompts, list_of_source_completions, 0, trainings_units, s, \"restriction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: She spends her time unwisely.\n",
      "Target Domain: time\n",
      "Source Domain:money\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Even small magnets are sources of magnetism that can erase credit cards.\n",
      "Target Domain: force\n",
      "Source Domain:object, mover\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: I'm all charged up and full of energy\n",
      "Target Domain: people\n",
      "Source Domain:batteries\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: He turned all funny.\n",
      "Target Domain: change\n",
      "Source Domain:direction, motion, movement\n",
      "Extract the conceptual metaphor from the following sentence:\n",
      "Sentence: Daughter broke Covid restrictions against the rules of the house\n",
      "Target Domain: restriction\n",
      "Source Domain:\n"
     ]
    }
   ],
   "source": [
    "print(analysis_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT3_analysis_completions=[]\n",
    "for p in analysis_prompts[:10]:\n",
    "    c = openai.Completion.create(\n",
    "            model=\"text-davinci-002\",\n",
    "            prompt=p,\n",
    "            max_tokens=14,\n",
    "            temperature=0\n",
    "        )\n",
    "    GPT3_analysis_completions.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daughter broke Covid restrictions against the rules of the house\n",
      "Predicted Source Domain: prison\n",
      "\n",
      "Farmers Mother of all protests still going ahead next month despite Covid-19 restrictions\n",
      "Predicted Source Domain: containment, enclosure\n",
      "\n",
      "Illinois trying to legislate Covid restrictions... ?\n",
      "Predicted Source Domain:  law\n",
      "\n",
      "@Reuters: Biden issuing new order lifting COVID-19 travel restrictions, imposing vaccine rules https://t.co/pZogUEwyLV https://t.co/EoRYNpqFlr\n",
      "Predicted Source Domain:  travel\n",
      "\n",
      "COVID restrictions in Prague?\n",
      "Predicted Source Domain: prison\n",
      "\n",
      "Parents, has covid restrictions added more or less pressure on you to be a Super Parent?\n",
      "Predicted Source Domain: weight, pressure\n",
      "\n",
      "Advice for friend circumventing COVID restrictions\n",
      "Predicted Source Domain: obstacle, blockage\n",
      "\n",
      "[World] - Slovakia extends COVID-19 restrictions amid infection surge | Toronto Star\n",
      "Predicted Source Domain: containment\n",
      "\n",
      "[World] - Slovakia extends COVID-19 restrictions amid infection surge\n",
      "Predicted Source Domain: containment\n",
      "\n",
      "Slovakia extends COVID-19 restrictions amid infection surge\n",
      "Predicted Source Domain: containment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(GPT3_analysis_completions)):\n",
    "    print(sentences_to_analyse[i])\n",
    "    print(\"Predicted Source Domain:\", GPT3_analysis_completions[i].choices[0].text)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
